{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8118aa",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a81bb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medmnist in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (1.19.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (0.25.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (0.22.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (0.18.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (4.41.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (6.2.1)\n",
      "Requirement already satisfied: fire in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (0.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (2.1.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from medmnist) (0.16.1+cu118)\n",
      "Requirement already satisfied: six in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from fire->medmnist) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from fire->medmnist) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from pandas->medmnist) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from pandas->medmnist) (2023.3.post1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from scikit-image->medmnist) (1.10.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from scikit-image->medmnist) (3.1.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from scikit-image->medmnist) (3.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from scikit-image->medmnist) (2.6.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from scikit-image->medmnist) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from scikit-image->medmnist) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from scikit-learn->medmnist) (1.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from torch->medmnist) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from torch->medmnist) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from torch->medmnist) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from torch->medmnist) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from torch->medmnist) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from torchvision->medmnist) (2.28.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (1.4.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->medmnist) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from jinja2->torch->medmnist) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from requests->torchvision->medmnist) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from requests->torchvision->medmnist) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from requests->torchvision->medmnist) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from requests->torchvision->medmnist) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\henrr\\anaconda3\\envs\\dmcnet\\lib\\site-packages (from sympy->torch->medmnist) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9e0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e514a5",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d4a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epoches = 3\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO['pathmnist']\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01262a",
   "metadata": {},
   "source": [
    "## Data Processing and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0460dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\henrr\\.medmnist\\pathmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\henrr\\.medmnist\\pathmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\henrr\\.medmnist\\pathmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\henrr\\.medmnist\\pathmnist.npz\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "#path = '../Dataset/pneumoniamnist.npz'\n",
    "#data = np.load(path)\n",
    "\n",
    "#Split data\n",
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=True)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=True)\n",
    "val_dataset = DataClass(split='val', transform=data_transform, download=True)\n",
    "pil_dataset = DataClass(split='train', download=True)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*batch_size, shuffle=False)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=2*batch_size, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9654991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset PathMNIST (pathmnist)\n",
      "    Number of datapoints: 89996\n",
      "    Root location: C:\\Users\\henrr\\.medmnist\n",
      "    Split: train\n",
      "    Task: multi-class\n",
      "    Number of channels: 3\n",
      "    Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
      "    Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
      "    Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
      "    License: CC BY 4.0\n",
      "===================\n",
      "Dataset PathMNIST (pathmnist)\n",
      "    Number of datapoints: 10004\n",
      "    Root location: C:\\Users\\henrr\\.medmnist\n",
      "    Split: val\n",
      "    Task: multi-class\n",
      "    Number of channels: 3\n",
      "    Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
      "    Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
      "    Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
      "    License: CC BY 4.0\n",
      "===================\n",
      "Dataset PathMNIST (pathmnist)\n",
      "    Number of datapoints: 7180\n",
      "    Root location: C:\\Users\\henrr\\.medmnist\n",
      "    Split: test\n",
      "    Task: multi-class\n",
      "    Number of channels: 3\n",
      "    Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
      "    Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
      "    Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
      "    License: CC BY 4.0\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(\"===================\")\n",
    "print(val_dataset)\n",
    "print(\"===================\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0c245",
   "metadata": {},
   "source": [
    "## ResNet-18 construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a7e91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "# ResNet-18\n",
    "class ResidualBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inCh, outCh, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inCh, out_channels=outCh, \n",
    "                            kernel_size=3, padding=1, stride=stride),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=outCh, out_channels=outCh, \n",
    "                            kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(outCh)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inCh != outCh:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inCh, out_channels=outCh, \n",
    "                            kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outCh)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, classes=9):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer_1 = self.make_layer(ResidualBlock, 64, 64, stride=1)\n",
    "        self.layer_2 = self.make_layer(ResidualBlock, 64, 128, stride=2)\n",
    "        self.layer_3 = self.make_layer(ResidualBlock, 128, 256, stride=2)\n",
    "        self.layer_4 = self.make_layer(ResidualBlock, 256, 512, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d((3, 3), stride=2)\n",
    "        self.fc = nn.Linear(512 * ResidualBlock.expansion, self.classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layer(self, block, inCh, outCh, stride, block_num=2):\n",
    "        layers = []\n",
    "        layers.append(block(inCh, outCh, stride))\n",
    "        for i in range(block_num - 1):\n",
    "            layers.append(block(outCh, outCh, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "model = ResNet18(classes=n_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab53d1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a1c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 704/704 [16:23<00:00,  1.40s/it]\n",
      "  0%|                                                                                          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: 0.0010554420296102762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 704/704 [16:19<00:00,  1.39s/it]\n",
      "  0%|                                                                                          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2  Loss: 0.0008726844098418951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                         | 62/704 [01:26<14:33,  1.36s/it]"
     ]
    }
   ],
   "source": [
    "# train\n",
    "loss_list = []\n",
    "\n",
    "if torch.cuda.is_available(): # training by using GPU if available\n",
    "        print('Training on GPU ...')\n",
    "        for epoch in range(num_epoches):\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "    \n",
    "            model.train()\n",
    "    \n",
    "            for inputs, targets in tqdm(train_loader):\n",
    "            # forward + backward + optimize\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                targets = targets.squeeze().long()\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loss_list.append(loss/len(train_loader))\n",
    "            \n",
    "            print('Epoch: {}  Loss: {}'.format(epoch+1, loss/len(train_loader)))\n",
    "            \n",
    "        print('Training finished')\n",
    "    \n",
    "else:\n",
    "    print('Training on CPU ...')\n",
    "    for epoch in range(num_epoches):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "    \n",
    "        model.train()\n",
    "    \n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "        # forward + backward + optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.squeeze().long()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_list.append(loss/len(train_loader))\n",
    "\n",
    "        print('Epoch: {}  Loss: {}'.format(epoch+1, loss/len(train_loader)))\n",
    "        \n",
    "    print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0673719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# training loss curve\n",
    "iterition = range(num_epoches)\n",
    "Loss = loss_list\n",
    "\n",
    "plt.plot(iterition, Loss, '-')\n",
    "plt.title('Training loss vs. epoches')\n",
    "plt.ylabel('Training loss')\n",
    "plt.xlabel('epoches')\n",
    "# plt.savefig('./loss1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40a9a3",
   "metadata": {},
   "source": [
    "## Save Model Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c37171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model trained\n",
    "# torch.save(model.state_dict(), 'checkpoint_resnet100.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d0471",
   "metadata": {},
   "source": [
    "## Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda313cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "def test(split):\n",
    "    model.eval()\n",
    "    y_true = torch.Tensor([])\n",
    "    y_score = torch.Tensor([])\n",
    "    if torch.cuda.is_available(): # testing by using GPU if available\n",
    "        y_true, y_score = y_true.cuda(), y_score.cuda()\n",
    "        if split =='train':\n",
    "            data_loader = train_loader_at_eval\n",
    "        elif split =='test':\n",
    "            data_loader = test_loader\n",
    "        elif split =='val':\n",
    "            data_loader = val_loader\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in data_loader:\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                outputs = model(inputs)\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "                y_true = torch.cat((y_true, targets), 0)\n",
    "                y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "\n",
    "        evaluator = Evaluator('pathmnist', split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    \n",
    "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "        \n",
    "    else:\n",
    "        if split =='train':\n",
    "            data_loader = train_loader_at_eval\n",
    "        elif split =='test':\n",
    "            data_loader = test_loader\n",
    "        elif split =='val':\n",
    "            data_loader = val_loader\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in data_loader:\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                outputs = model(inputs)\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "                y_true = torch.cat((y_true, targets), 0)\n",
    "                y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.numpy()\n",
    "        y_score = y_score.detach().numpy()\n",
    "\n",
    "        evaluator = Evaluator('pneumoniamnist', split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    \n",
    "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "\n",
    "        \n",
    "print('==> Evaluating ...')\n",
    "train_result = test('train')\n",
    "val_result = test('val')\n",
    "test_result = test('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317d655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DMCNet]",
   "language": "python",
   "name": "conda-env-DMCNet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
